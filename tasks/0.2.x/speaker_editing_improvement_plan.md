# 話者編集機能 改善実装方針書

## 1. 概要

本ドキュメントは、既存の「transcript-minute」アプリケーションにおいて、話者編集機能を改善するための実装方針を定義する。
主な改善点は以下の通り。

1.  **話者の個別編集機能**: 現在の一括割り当て方式に加え、AIによる話者分離が不正確だった場合に備え、ユーザーが個々の発言ブロックごとに話者を修正できる機能を追加する。
2.  **音声プレビュー機能**: 編集の正確性を向上させるため、文字起こしされたテキストの特定部分をクリックすると、元の音声ファイルの該当箇所を再生できる機能を追加する。

これらの機能により、より正確で柔軟な文字起こし結果の編集体験を提供し、ユーザーの満足度を向上させることを目指す。

## 2. ElevenLabs API 仕様 (Speech to Text)

本機能、特に音声プレビュー機能の実装において、ElevenLabs APIから返却されるタイムスタンプ情報が重要となる。

- **Endpoint**: `POST /v1/speech-to-text`
- **Response Body (抜粋)**:
  ```json
  {
    "language_code": "en",
    "language_probability": 0.98,
    "text": "Hello world!",
    "words": [
      {
        "text": "Hello",
        "type": "word",
        "logprob": -0.124,
        "start": 0.0,
        "end": 0.5,
        "speaker_id": "speaker_1"
      },
      {
        "text": " ",
        "type": "spacing",
        "logprob": 0,
        "start": 0.5,
        "end": 0.5,
        "speaker_id": "speaker_1"
      },
      {
        "text": "world!",
        "type": "word",
        "logprob": -0.089,
        "start": 0.5,
        "end": 1.2,
        "speaker_id": "speaker_1"
      }
    ]
  }
  ```
- **重要なキー**:
  - `words`: 単語ごとの情報を含む配列。
    - `text`: 文字起こしされた単語。
    - `start`: 音声ファイル内での単語の開始時間（秒）。
    - `end`: 音声ファイル内での単語の終了時間（秒）。
    - `speaker_id`: その単語を話した話者のID。

この`start`と`end`を利用して音声の再生位置を特定し、`speaker_id`を編集対象とする。

## 3. 実装方針

### 3.1 中間ファイル (タイムスタンプ付きJSON) の設計

**現状の課題**:
単一の長大な文字列で文字起こし情報を管理しているため、タイムスタンプ情報が失われており、個別編集や音声再生に対応できない。また、ElevenLabsのAPIレスポンスをそのまま保存する案は、ファイルサイズが冗長で、将来の音声前処理（無音カット等）を考慮した際の柔軟性に欠ける。

**新しい方針**:
バックエンドとフロントエンドで利用する中間ファイルとして、**必要な情報のみを抽出したカスタムJSON形式**を定義し、利用する。

1.  **中間ファイルの形式 (カスタムJSON)**:
    `transcriptionProcessor` Lambdaは、ElevenLabsのAPIレスポンスから以下の情報を持つJSONファイルを生成し、`transcript.json`のような名前でS3に保存する。

    ```json
    {
      "schema_version": "1.0",
      "audio_duration": 3605.5,
      "language": "ja",
      "preprocessing_info": null,
      "words": [
        { "text": "こんにちは", "start": 0.5, "end": 1.2, "speaker_id": "speaker_1" },
        { "text": "、", "start": 1.2, "end": 1.2, "speaker_id": "speaker_1" },
        // ... 以降、単語ごとの情報が続く
      ]
    }
    ```

    - `schema_version`: 将来的にこのJSON構造を変更する際に後方互換性を保つためのバージョン情報。
    - `audio_duration`: 元の音声ファイルの総時間（秒）。音声プレビューUIのプログレスバー表示などに利用できる。
    - `language`: 検出された言語コード。
    - `preprocessing_info`: 将来の音声前処理（無音カット等）で発生したタイムスタンプのオフセット等の補正情報を格納するための予約領域。今回は`null`とする。
    - `words`: ElevenLabs APIレスポンスの`words`配列。単語ごとのテキスト、開始/終了時間、話者IDが含まれ、話者の個別編集と音声再生機能の根幹となる。

2.  **フロントエンドでの利用**:
    - 話者編集画面では、まずこの中間JSONファイルをS3から取得する。
    - **取得した`words`配列を元に、UI表示用の「発言ブロック」オブジェクトの配列 (`SpeechSegment[]`) をメモリ上に構築する。** これは、連続する同じ`speaker_id`の`words`を一つのブロックにまとめるクライアントサイドの処理である。この設計により、将来的にブロックを分割するなどの高度な編集にも対応できる柔軟性を確保する。
        ```typescript
        // メモリ上で管理する発言ブロックの型 (変更なし)
        interface SpeechSegment {
          id: string; 
          speakerId: string;
          speakerName: string;
          startTime: number;
          endTime: number;
          text: string;
          words: Word[];
        }
        ```
    - ユーザーによる編集操作は、すべてこのメモリ上の`SpeechSegment[]`に対して行われる。

### 3.2 UI/UXの設計

**現状の課題**:
話者リストと全体のプレビューのみで構成されており、個別編集の概念がない。

**新しい方針**:

1.  **発言ブロックごとのUI**:
    *   文字起こしプレビューを、発言ブロック (`SpeechSegment`) ごとに分割して表示する。
    *   各ブロックの隣に、話者を変更するための**ドロップダウンメニュー**を設置する。ドロップダウンには、検出された話者（speaker_1, speaker_2...）と、ユーザーがすでに入力した名前の一覧が表示される。
    *   「新しい話者を追加」オプションも提供する。

2.  **音声再生のトリガー**:
    *   各発言ブロックのテキスト部分をクリックすると、そのブロックの`startTime`から`endTime`までの音声を再生する。
    -   再生中は、該当ブロックの背景色を変えたり、再生アイコンを表示したりするなど、視覚的なフィードバックを提供する。
    - 音声再生用のUI（再生/一時停止ボタン、シークバーなど）もブロック内に表示する。
    - UI上の分かりやすい場所（例: 「編集を完了」ボタンの近く）に、「編集を完了した後は、音声の再生や話者の再編集ができなくなります。」という注意書きを常に表示しておく。

### 3.3 音声再生の実装

**方針**:
`HTMLAudioElement`を直接利用して、部分再生機能を実装する。

1.  **音声ファイルの読み込み**:
    *   文字起こし対象となった元の音声ファイル（MP3, WAV等）を`<audio>`タグで読み込む。UI上では非表示にしておく。
2.  **再生ロジック**:
    *   ユーザーが発言ブロックをクリックした際に、JavaScriptで以下の処理を実行する。
        ```javascript
        const audio = document.getElementById('audio-player'); // <audio>要素
        audio.currentTime = segment.startTime; // 再生開始位置を設定
        audio.play();
        ```
    *   `endTime`に達したら再生を自動的に停止させるため、`timeupdate`イベントを監視し、`audio.currentTime >= segment.endTime`になったら`audio.pause()`を呼び出す。

### 3.4 最終成果物 (プレーンテキスト) の生成と保存

**方針**:
ユーザーが話者編集を完了した時点で、**可読性の高いプレーンテキスト形式**の最終成果物を生成し、S3に保存する。この処理は、以降のコンテンツ生成（箇条書き、議事録）やダウンロード機能との連携をスムーズにするために重要である。

1.  **最終成果物の形式**:
    - ユーザーに提供し、後続の処理で利用するファイルは、`[話者名]:`を基本とし、話者交代時に空行を挟むことで可読性を高めた形式とする。
      ```text
      [山田太郎]:
      こんにちは、本日の会議を始めます。議題は...

      [鈴木花子]:
      よろしくお願いいたします。
      最初の議題についてですが...
      ```
    - **実装上の注意**: プレビュー表示と最終出力の両方で、この形式に統一すること。Markdown形式（`**[話者名]**`）は使用しない。

2.  **生成のタイミングと担当**:
    - **タイミング**: ユーザーが話者編集画面で「編集を完了」ボタンをクリックした時。
    - **担当**: フロントエンド。

3.  **テキスト再構築ロジック**:
    - フロントエンドは、メモリ上で管理している`SpeechSegment[]`配列（ユーザーの編集がすべて反映された状態）を元に、上記のテキスト形式を生成する。
    - 具体的には、`SpeechSegment[]`配列をループ処理し、各ブロックについて`[話者名]:\n発言内容\n\n`といった文字列を生成・結合する。（`\n`はプログラム上の改行コードであり、実際のファイルでは改行として表示される）

4.  **S3への保存**:
    - 生成されたプレーンテキストを、S3にアップロードする。
    - **重要**: アップロード先は、`ProcessingSession`の`transcriptKey`が指すパスとし、**既存の中間JSONファイルをこのプレーンテキストで上書きする**。
    - この上書き方式により、後続の`generationWorker` Lambdaやダウンロード処理は、既存の「テキストファイルをS3から読み込む」という実装を大きく変更することなく動作できる。

5.  **制約事項**:
    - 編集を完了してテキスト形式で保存すると、タイムスタンプ情報を含む中間JSONは失われる。
    - これにより、**一度編集を完了したセッションは、音声プレビュー付きの話者再編集はできなくなる**。この制約はUI上の注意書きでユーザーに伝える。

### 3.5 音声ファイルの安全な取得方法

フロントエンドがS3上の音声ファイルを安全に再生するため、バックエンドに署名付きURLを要求する仕組みを導入する。

1.  **役割**: フロントエンドは、`ProcessingSession`のIDをキーとしてバックエンドに音声ファイルのURLを要求する。バックエンドは、S3入力バケット内の該当ファイルに対する、有効期限付きの読み取り専用URL（署名付きURL）を生成して返す。
2.  **インターフェース**: 新しいGraphQLクエリを`Query`型に追加する。
    ```graphql
    # schema.graphql
    type Query {
      # ...既存のクエリ
      getAudioPresignedUrl(sessionId: ID!): String
    }
    ```
3.  **実装**: このクエリは、Amplifyのカスタムリゾルバーを用いて実装する。リゾルバーは、リクエスト元のユーザーがセッションの所有者であることを検証した上で、S3 SDKを呼び出して署名付きURLを生成する。

**TODO: 実装詳細**
- `getAudioPresignedUrl` クエリは、専用のLambda関数を作成して実装する必要がある。
- この関数は、`ProcessingSession`のIDを受け取り、該当するセッションの音声ファイルに対する署名付きURLを生成する。
- セキュリティ上、リクエスト元のユーザーがセッションの所有者であることを検証する必要がある。
- Lambda関数の作成は、`amplify add function` コマンドを使用し、GraphQLリゾルバーとして設定する。

### 3.6 編集状態の管理

文字起こし結果が「編集可能な中間JSON形式」なのか、「編集済みの最終テキスト形式」なのかを明確に区別し、UIの表示を制御するための仕組みを導入する。

**重要な変更**: 実装の簡潔性と可読性を重視し、新しい方式（JSON形式）のみをサポートすることとした。既存のTEXT形式のセッションは考慮しない。

1.  **役割**: `ProcessingSession`に、文字起こしファイルの形式を示すステータスを持たせる。
    - `JSON`: タイムスタンプ付きの中間ファイル。話者編集画面を開ける状態。
    - `TEXT`: 編集済みの最終テキストファイル。話者編集はできず、結果表示のみとなる状態。
2.  **インターフェース**: `ProcessingSession`に新しいフィールドを追加し、その型として`enum`を定義する。
    ```graphql
    # schema.graphql
    enum TranscriptFormat {
      JSON
      TEXT
    }

    type ProcessingSession @model {
      # ... 既存のフィールド ...
      transcriptFormat: TranscriptFormat
    }
    ```
3.  **処理フロー**:
    - **生成時**: `transcriptionProcessor` Lambdaが中間JSONを生成した後、`transcriptFormat`を`JSON`に設定して`ProcessingSession`を更新する。
    - **完了時**: フロントエンドが「編集を完了」してプレーンテキストをS3に上書き保存する際、同時に`transcriptFormat`を`TEXT`に更新するミューテーションを呼び出す。
    - **UI制御**: フロントエンドは、`transcriptFormat`の値に応じて「話者を編集する」ボタンの表示/非表示を切り替える。

## 4. 実装の進め方

1.  **バックエンド修正**: `transcriptionProcessor` Lambdaを修正し、ElevenLabsのレスポンスJSONをそのままS3に保存するように変更する。
2.  **フロントエンド データ読み込み**: `SpeakerNameEditor`コンポーネントが、S3からテキストではなくJSONを読み込み、`SpeechSegment[]`の内部状態を構築できるようにする。
3.  **UI実装（個別編集）**: 発言ブロックごとのドロップダウンリストと、状態更新ロジックを実装する。
4.  **UI実装（音声再生）**: `<audio>`要素を配置し、クリックイベントに応じた部分再生機能を実装する。
5.  **保存処理実装**: `SpeechSegment[]`からテキストを再構築し、S3にアップロードする機能を実装する。
6.  **テストと調整**: 全ての機能が連携して動作することを確認し、UI/UXを微調整する。

## 5. バックエンド変更点の概要 (GraphQL スキーマ)

本改修に伴い、`amplify/backend/api/transcriptminute/schema.graphql` に以下の変更を加える。

1.  **`Query`型の変更**:
    - 音声再生用の署名付きURLを取得するクエリを追加する。
      ```graphql
      getAudioPresignedUrl(sessionId: ID!): String
      ```

2.  **`TranscriptFormat` enumの新規追加**:
    - 文字起こしファイルの形式を表現するenumを定義する。
      ```graphql
      enum TranscriptFormat {
        JSON
        TEXT
      }
      ```

3.  **`ProcessingSession`型の変更**:
    - 上記の`TranscriptFormat`を型とするフィールドを追加する。
      ```graphql
      type ProcessingSession @model {
        # ...
        transcriptFormat: TranscriptFormat
        # ...
      }
      ``` 